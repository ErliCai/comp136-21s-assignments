{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 135 day05 Lab: Univariate Gaussian distributions\n",
    "\n",
    "## Outline\n",
    "\n",
    "* **Part 1: Univariate Gaussian Distribution Basics**\n",
    "* * Learn to sample from a univariate Gaussian\n",
    "\n",
    "* **Part 2: ML Estimators and biased vs unbiased**\n",
    "* * Simulate finite sample from true model, then estimate from that sample. Repeat many times.\n",
    "\n",
    "* **Part 3: Properties of the univariate Gaussian**\n",
    "* * Visualize linear transformations of Gaussian samples\n",
    "* * Visualize sums of Gaussian samples\n",
    "* * Visualize products of Gaussian samples\n",
    "* * Learn to evaluate PDF of a univariate Gaussian and plot it alongside a histogram\n",
    "\n",
    "## Skills \n",
    "\n",
    "* To draw samples:\n",
    "* * [`scipy.stats.norm(loc=..., scale=...).rvs(size=(nrows,ncols), random_state=SEED)`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html)\n",
    "* * OR [`np.random.normal(loc=..., scale=...)`](https://numpy.org/doc/stable/reference/random/generated/numpy.random.normal.html)\n",
    "* To evaluate the PDF:\n",
    "* * Evaluate pdf with `scipy.stats.norm(loc=..., scale=...).pdf(values)`\n",
    "* * Evaluate logpdf with `logpdf` instead of `pdf`\n",
    "\n",
    "\n",
    "## Takeaways\n",
    "\n",
    "* Linear transforms of Gaussian variables are also Gaussian distributed\n",
    "* The sum of Gaussian variables is also Gaussian distributed\n",
    "* The product of Gaussian variables is *not* Gaussian distributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:,.3g}'.format  # show 3 digits of precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"notebook\", font_scale=1.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Univariate Gaussian basics\n",
    "\n",
    "## Univariate Gaussian background\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Random Variable: Scalar data $x \\in \\mathbb{R}$\n",
    "\n",
    "This is a scalar real value.\n",
    "\n",
    "#### Parameters: Location $\\mu$ and scale $\\sigma$\n",
    "\n",
    "* Location or \"mean\" is just any real value: $\\mu \\in \\mathbb{R}$\n",
    "* Scale or standard-deviation $\\sigma$ must be a positive value: $\\sigma > 0$\n",
    "\n",
    "We can also call *square* of the  \"scale\" parameter the *variance*: $\\sigma^2$\n",
    "\n",
    "#### Formal definition of PDF: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\text{NormPDF}\\left( x | \\mu, \\sigma^2 \\right) \n",
    "    = c(\\mu, \\sigma) \\cdot e^{-\\frac{1}{2} \\frac{1}{\\sigma^2} (x - \\mu)^2 }\n",
    "\\end{align}\n",
    "\n",
    "with normalizing \"constant\" (a term constant wrt our random variable $x$):\n",
    "\n",
    "$$\n",
    "c(\\mu, \\sigma) = \\frac{1}{(2\\pi)^{1/2}} \\frac{1}{\\sigma}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sampling from the \"standard\" univariate Gaussian\n",
    "\n",
    "It is common to think about the Gaussian with zero mean and variance one.\n",
    "Call this the \"standard\" normal or \"standard\" Gaussian.\n",
    "\n",
    "We can use `np.random.randn` to sample from the standard normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set our random state so things are reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng = np.random.RandomState(11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw several samples from the *standard* Normal (*standard* means zero mean and unit variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng.randn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng.randn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw 1000 samples and plot the histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "x_N = prng.randn(N)\n",
    "sns.histplot(x_N);\n",
    "plt.xlim([-3.5, 3.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "x_N = prng.randn(N)\n",
    "sns.histplot(x_N);\n",
    "plt.xlim([-3.5, 3.5]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Sampling from the *general* univariate Gaussian\n",
    "\n",
    "Here, we'll assume that the mean and variance of the Gaussian are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 11.22\n",
    "sigma = 3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng.normal(loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prng.normal(loc=mu, scale=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1a: Write code to plot a histogram of samples with $\\mu = -1, \\sigma = 3$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "# TODO draw samples (hint: use prng.normal with provided loc and scale)\n",
    "# TODO plot histogram (hint: see lines above for calls to sns.histplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1b: Write code to plot a histogram of samples with $\\mu = -5, \\sigma = 0.2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "# TODO draw samples (hint: use prng.normal with provided loc and scale)\n",
    "# TODO plot histogram (hint: see lines above for calls to sns.histplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion 1c: Can you use the plots above to come up with reasonable rules for the \"high density\" regions of the univariate normal?\n",
    "\n",
    "* A \"super-majority\" of samples (say 2/3 or ~67%) will occur between $\\mu - a$ and $\\mu + a$\n",
    "* Almost all samples (say ~99%) will occur between $\\mu - b$ and $\\mu + b$\n",
    "\n",
    "How should we pick $a$ and $b$? Can they be constants? Or should they depend on $\\mu$ or $\\sigma$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1d: Try out your rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 101.0\n",
    "sigma = 15.0\n",
    "a = 0.0 # TODO fix me\n",
    "b = 0.0 # TODO fix me\n",
    "\n",
    "N = 10000\n",
    "x_N = prng.normal(loc=mu, scale=sigma, size=N)\n",
    "\n",
    "n_match_for_a = np.sum(np.logical_and(x_N >= mu - a, x_N <= mu + a))\n",
    "n_match_for_b = np.sum(np.logical_and(x_N >= mu - b, x_N <= mu + b))\n",
    "\n",
    "print(\"%.2f samples occur between mu - %.2f and mu + %.2f\" % (n_match_for_a/N, a, a))\n",
    "print(\"%.2f samples occur between mu - %.2f and mu + %.2f\" % (n_match_for_b/N, b, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Unbiased vs. Biased estimation of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pre-recorded videos, we developed the following estimators using the *maximum likelihood* principle:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat{\\mu} &= \\frac{1}{N} \\sum_{n=1}^N x_n\n",
    "\\\\\n",
    "\\hat{\\sigma}^2 &= \\frac{1}{N} \\sum_{n=1}^N (x_n - \\hat{\\mu} )^2\n",
    "\\end{align}\n",
    "\n",
    "We further learned that:\n",
    "  \n",
    "* the ML-estimator for the mean is *unbiased*\n",
    "* the ML-estimator for the variance is *biased*\n",
    "\n",
    "Here, we're gonna work on *demonstrating* this bias (or lack there of) via simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2a: Implement the ML estimation formulas in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ml_estimates_for_mean_and_variance(x_N):\n",
    "    ''' Compute the ML estimators for Gaussian parameters given N observed data\n",
    "    \n",
    "    Args\n",
    "    ----\n",
    "    x_N : 1D array, shape (n_examples,) = (N,)\n",
    "        N iid observations to be modeled as draws from a univariate Gaussian\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mu_hat : float\n",
    "    sigma_squared_hat : float, must be positive\n",
    "    '''\n",
    "    mu_hat = 0.0 # TODO fix me\n",
    "    sigma_squared_hat = 1.0 # TODO fix me\n",
    "    return mu_hat, sigma_squared_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2b: Implement simulations that repeatedly generate data from true model and then estimate parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_many_simulations(n_trials=1000, N=10, mu_true=1.0, sigma_squared_true=1.0):\n",
    "    ''' Produce estimates of parameters for many trials of a toy data experiment\n",
    "    \n",
    "    Each trial will:\n",
    "    * Draw N samples of x_n ~ Normal(mean=mu_true, variance=sigma_squared_true)\n",
    "    * Compute ML estimates using these samples\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    mu_hat_R : 1D array, shape (n_trials,) = (R,)\n",
    "        Contains mu_hat estimate for each trial\n",
    "    sigma_squared_hat_R : 1D array, shape (n_trials,) = (R,)\n",
    "        Contains sigma_squared_hat estimate for each trial\n",
    "    '''\n",
    "    mu_hat_list = list()\n",
    "    sigma_squared_hat_list = list()\n",
    "    for trial in range(n_trials):\n",
    "        x_N = np.zeros(N) # TODO draw N samples of x from a Gaussian with mu_true and sigma_squared_true\n",
    "        assert x_N.shape == (N,)\n",
    "\n",
    "        # Use your function from 2a to get estimates of the parameters\n",
    "        mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(x_N)\n",
    "\n",
    "        # Record these estimates in a big list\n",
    "        mu_hat_list.append(mu_hat)\n",
    "        sigma_squared_hat_list.append(sigma_squared_hat)\n",
    "    return np.asarray(mu_hat_list), np.asarray(sigma_squared_hat_list)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2c: Run simulations with R=200 trials and N=10 samples\n",
    "\n",
    "We'll visualize the *distribution* of our estimator across trials.\n",
    "\n",
    "We'll also look at how well the *average result* of these trials matches our *true* parameter.\n",
    "\n",
    "Run the code below. No need to edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_true = 30.0;             # Keep this at 30\n",
    "sigma_squared_true = 10.0;  # Keep this at 10\n",
    "N = 10\n",
    "R = 200\n",
    "\n",
    "mu_hat_R, sigma_squared_hat_R = run_many_simulations(\n",
    "    n_trials=R, N=N, mu_true=mu_true, sigma_squared_true=sigma_squared_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize true $\\mu$ and estimates from many trials\n",
    "\n",
    "Just run the code below to produce a visual. You don't need to edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_hat_mean = np.mean(mu_hat_R);\n",
    "print(\"Empirical average value of \\hat{\\mu} = %.2f over %d trials\" % (mu_hat_mean, R))\n",
    "\n",
    "# Plot histogram of mu_hats across all R trials\n",
    "sns.histplot(mu_hat_R, color='g', alpha=0.4);\n",
    "\n",
    "# Plot \"true\" mu and \"mean\" mu as vertical lines\n",
    "plt.plot(mu_hat_mean * np.ones(2), np.asarray([0, plt.gca().get_ylim()[1]]), 'g--', label='empirical $E[\\hat{\\mu}]$');\n",
    "plt.plot(mu_true * np.ones(2), np.asarray([0, plt.gca().get_ylim()[1]]), 'b--', label='$\\mu_{true}$');\n",
    "plt.legend(bbox_to_anchor=(1.0, 0.8));\n",
    "\n",
    "plt.title(\"Distribution of $\\hat{\\mu}$ over R=%d trials with N=%d\" % (R, N));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare true $\\sigma^2$ and estimates from many trials\n",
    "\n",
    "Just run the code below to produce a visual. You don't need to edit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma_squared_hat_mean = np.mean(sigma_squared_hat_R);\n",
    "print(\"Empirical average value of \\hat{\\sigma}^2 = %.2f\" % sigma_squared_hat_mean)\n",
    "\n",
    "sns.histplot(sigma_squared_hat_R, color='m', alpha=0.2);\n",
    "\n",
    "# Plot \"true\" sigma and \"mean\" sigma_hat as vertical lines\n",
    "plt.plot(sigma_squared_hat_mean * np.ones(2), np.asarray([0, plt.gca().get_ylim()[1]]), 'm--', label='$E[ \\hat{\\sigma}^2]$');\n",
    "plt.plot(sigma_squared_true * np.ones(2), np.asarray([0, plt.gca().get_ylim()[1]]), 'r--', label='$\\sigma^2_{true}$');\n",
    "plt.legend(loc='upper right');\n",
    "\n",
    "plt.title(\"Distribution of $\\hat{\\sigma}^2$ over R=%d trials with N=%d\" % (R, N));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2d: Repeat the above with $R=10000$ trials (still keep $N=10$)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO copy code here and edit as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion 2e: Do you see the bias for sigma? Do you see a \"lack\" of bias for mu?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO discuss. What visually in the plots above reveals \"bias\"? Do the patterns you see change with many trials?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion 2f: Does the amount of bias agree with derivations?\n",
    "\n",
    "Remember, we suggested that:\n",
    "    \n",
    "$$\n",
    "\\mathbb{E}[ \\hat{\\sigma}^2 ] = \\frac{N-1}{N} \\sigma_{\\text{true}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO discuss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Visualizing transformations of Gaussians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3a: Linear transformations of Gaussians\n",
    "\n",
    "* 1) Drawn 10000 samples of $X$ a standard Normal.\n",
    "* 2) Transform each $X$ into $Y$, using linear transform $Y \\gets 3 X + 2$\n",
    "* 3) Draw the histograms of the resulting distributions\n",
    "* 4a) Add a PDF plot for ML-estimated parameters using the samples of $X$\n",
    "* 4b) Add a PDF plot for ML-estimated parameters using the samples of $Y$\n",
    "\n",
    "Note that there are coding TODOs only for 1 and 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Draw samples \n",
    "x_N = prng.randn(10000)\n",
    "\n",
    "# STEP 2: Apply linear transform: Y = 3 * X + 2\n",
    "y_N = prng.rand(10000) # TODO replace with transform\n",
    "\n",
    "# STEP 3: Draw histograms\n",
    "fig, axgrid = plt.subplots(nrows=2, ncols=1, sharex=True, sharey=True, figsize=(10, 5))\n",
    "sns.histplot(x_N, color='b', alpha=0.2, ax=axgrid[0], bins=np.linspace(-8, 12, 51), stat='density');\n",
    "sns.histplot(y_N, color='r', alpha=0.2, ax=axgrid[1], bins=np.linspace(-8, 12, 51), stat='density');\n",
    "\n",
    "# STEP 4a: Compute ML-estimates of parameters for X\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(x_N)\n",
    "xgrid_G = np.linspace(-8, 12, 301);\n",
    "pdfgrid_G = np.zeros(xgrid_G.size) # TODO call scipy.stats.norm's pdf function to get the pdf\n",
    "axgrid[0].plot(xgrid_G, pdfgrid_G, 'b-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[0].legend(loc='upper right');\n",
    "axgrid[0].set_title('$X \\sim \\mathcal{N}(0, 1)$')\n",
    "\n",
    "# STEP 4b: Compute ML-estimates of parameters for Y\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(y_N)\n",
    "ygrid_G = np.linspace(-8, 12, 301);\n",
    "pdfgrid_G = np.zeros(ygrid_G.size) # TODO call scipy.stats.norm's pdf function to get the pdf\n",
    "axgrid[1].plot(ygrid_G, pdfgrid_G, 'r-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[1].legend(loc='upper right');\n",
    "axgrid[1].set_title('$Y = 3 X + 2$');\n",
    "\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion 3b: Does Y appear to be Gaussian distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO discuss. What clues did you use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3c: Sums of Gaussian random variables\n",
    "\n",
    "* 1a) Draw 10000 samples of $X$ from a standard Normal.\n",
    "* 1b) Draw 10000 samples of $Y$ from a standard Normal.\n",
    "\n",
    "* 2) Apply a sum transform: $Z = X+ Y$\n",
    "* 3) Draw the histograms of the resulting distributions\n",
    "\n",
    "* 4) Add a PDF plot for ML-estimated parameters using the samples of $Z$\n",
    "\n",
    "Note that there are coding TODOs only for 1 and 4\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Draw samples \n",
    "x_N = prng.randn(10000)\n",
    "y_N = prng.randn(10000)\n",
    "\n",
    "# STEP 2: Apply sum transform: Z = X + Y\n",
    "z_N = prng.rand(10000) # TODO replace with transform\n",
    "               \n",
    "# STEP 3: Draw histograms\n",
    "xmin = -4\n",
    "xmax = +4\n",
    "fig, axgrid = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(10, 8))\n",
    "sns.histplot(x_N, color='b', alpha=0.2, ax=axgrid[0], bins=np.linspace(xmin, xmax, 51), stat='density');\n",
    "sns.histplot(y_N, color='y', alpha=0.2, ax=axgrid[1], bins=np.linspace(xmin, xmax, 51), stat='density');\n",
    "sns.histplot(z_N, color='g', alpha=0.2, ax=axgrid[2], bins=np.linspace(xmin, xmax, 51), stat='density');\n",
    "\n",
    "# STEP 4a: Compute ML-estimates of parameters for X\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(x_N)\n",
    "xgrid_G = np.linspace(xmin, xmax, 301);\n",
    "pdfgrid_G = np.zeros(ygrid_G.size) # TODO call scipy.stats.norm's pdf function to get the pdf\n",
    "axgrid[0].plot(xgrid_G, pdfgrid_G, 'b-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[0].legend(loc='upper right');\n",
    "axgrid[0].set_title('$X \\sim \\mathcal{N}(0, 1)$')\n",
    "\n",
    "# STEP 4b: Compute ML-estimates of parameters for Y\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(y_N)\n",
    "ygrid_G = np.linspace(xmin, xmax, 301);\n",
    "pdfgrid_G = np.zeros(ygrid_G.size) # TODO call scipy.stats.norm's pdf function to get the pdf\n",
    "axgrid[1].plot(ygrid_G, pdfgrid_G, 'y-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[1].legend(loc='upper right');\n",
    "axgrid[1].set_title('$Y \\sim \\mathcal{N}(0, 1)$');\n",
    "\n",
    "# STEP 4b: Compute ML-estimates of parameters for Z\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(z_N)\n",
    "zgrid_G = np.linspace(xmin, xmax, 301);\n",
    "pdfgrid_G = np.zeros(ygrid_G.size) # TODO call scipy.stats.norm's pdf function to get the pdf\n",
    "axgrid[2].plot(zgrid_G, pdfgrid_G, 'g-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[2].legend(loc='upper right');\n",
    "axgrid[2].set_title('$Z = X + Y$');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion 3d: Does Z = X + Y above appear to be Gaussian distributed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO discuss!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3e: Products of Gaussian random variables\n",
    "\n",
    "* 1a) Draw 10000 samples of $X$ from a standard Normal.\n",
    "* 1b) Draw 10000 samples of $Y$ from a standard Normal.\n",
    "\n",
    "* 2) Apply a *product* transform: $Z = X * Y$\n",
    "* 3) Draw the histograms of the resulting distributions\n",
    "\n",
    "* 4) Add a PDF plot for ML-estimated parameters using the samples of $Z$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Draw samples \n",
    "x_N = prng.randn(10000)\n",
    "y_N = prng.randn(10000)\n",
    "\n",
    "# STEP 2: Apply product transform: Z = X * Y\n",
    "z_N = prng.rand(10000) # TODO replace with transform\n",
    "\n",
    "# STEP 3: Draw histograms\n",
    "xmin = -3\n",
    "xmax = +3\n",
    "fig, axgrid = plt.subplots(nrows=3, ncols=1, sharex=True, sharey=True, figsize=(10, 8))\n",
    "sns.histplot(x_N, color='b', alpha=0.2, ax=axgrid[0], bins=np.linspace(xmin, xmax, 51), stat='density');\n",
    "sns.histplot(y_N, color='y', alpha=0.2, ax=axgrid[1], bins=np.linspace(xmin, xmax, 51), stat='density');\n",
    "sns.histplot(z_N, color='g', alpha=0.2, ax=axgrid[2], bins=np.linspace(xmin, xmax, 51), stat='density');\n",
    "\n",
    "# STEP 4a: Compute ML-estimates of parameters for X\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(x_N)\n",
    "xgrid_G = np.linspace(xmin, xmax, 301);\n",
    "pdfgrid_G = np.zeros(xgrid_G.size) # TODO compute PDF\n",
    "axgrid[0].plot(xgrid_G, pdfgrid_G, 'b-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[0].legend(loc='upper right');\n",
    "axgrid[0].set_title('$X \\sim \\mathcal{N}(0, 1)$')\n",
    "\n",
    "# STEP 4b: Compute ML-estimates of parameters for Y\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(y_N)\n",
    "ygrid_G = np.linspace(xmin, xmax, 301);\n",
    "pdfgrid_G = np.zeros(xgrid_G.size) # TODO compute PDF\n",
    "axgrid[1].plot(ygrid_G, pdfgrid_G, 'y-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[1].legend(loc='upper right');\n",
    "axgrid[1].set_title('$Y \\sim \\mathcal{N}(0, 1)$');\n",
    "\n",
    "# STEP 4b: Compute ML-estimates of parameters for Z\n",
    "mu_hat, sigma_squared_hat = calc_ml_estimates_for_mean_and_variance(z_N)\n",
    "zgrid_G = np.linspace(xmin, xmax, 301);\n",
    "pdfgrid_G = np.zeros(xgrid_G.size) # TODO compute PDF\n",
    "axgrid[2].plot(zgrid_G, pdfgrid_G, 'g-', label=\"ML fit: $\\mu$=%.2f $\\sigma^2$=%.2f\" % (mu_hat, sigma_squared_hat));\n",
    "axgrid[2].legend(loc='upper right');\n",
    "axgrid[2].set_title('$Z = X * Y$');\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion 3f: Does Z = X * Y above appear to be Gaussian distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO discuss! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
